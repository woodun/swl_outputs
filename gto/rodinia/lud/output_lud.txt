

        *** GPGPU-Sim Simulator Version 3.2.2  [build 0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N:L,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N:L,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N:H,A:32:8,8:2,0,1:0:1:1:0:1,1:4:8:16:32:64,/sciclone/data10/hwang07/GPU_RESEARCH/swl/swl_outputs/RESULTS/gto/ # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PreShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gmem_skip_L1D                          0 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      15 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size                   49152 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:8,L:B:m:W:L,A:32:4,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            6 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBCCCCB.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file  gpuwattch_gtx480.xml # GPUWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 700.0:700.0:700.0:924.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 12
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000e100 	high:16 low:8
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000001eff 	high:13 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
sub_partition_id_mask = 0000000000000100
GPGPU-Sim uArch: clock freqs: 700000000.000000:700000000.000000:700000000.000000:924000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000142857142857:0.00000000142857142857:0.00000000142857142857:0.00000000108225108225
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 15
GPGPU-Sim uArch:    0   1   2   3   4
GPGPU-Sim uArch:    5   6   7   8   9
GPGPU-Sim uArch:   10  11  12  13  14
GPGPU-Sim uArch:   15  16  17  18  19
GPGPU-Sim uArch:   20  21  22  23  24
GPGPU-Sim uArch:   25  26
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 15
GPGPU-Sim uArch:    0   1   2   3   4
GPGPU-Sim uArch:    5   6   7   8   9
GPGPU-Sim uArch:   10  11  12  13  14
GPGPU-Sim uArch:   15  16  17  18  19
GPGPU-Sim uArch:   20  21  22  23  24
GPGPU-Sim uArch:   25  26
64481155cd105b68012fb0565c8bf7e9  /sciclone/data10/hwang07/adwait/applications/benchmarks/rodinia/cuda/lud/cuda/gpgpu_ptx_sim__lud
GPGPU-Sim uArch: performance model initialization complete.
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=lud_kernel.cu
self exe links to: /sciclone/data10/hwang07/adwait/applications/benchmarks/rodinia/cuda/lud/cuda/gpgpu_ptx_sim__lud
Running md5sum using "md5sum /sciclone/data10/hwang07/adwait/applications/benchmarks/rodinia/cuda/lud/cuda/gpgpu_ptx_sim__lud "
Parsing file _cuobjdump_complete_output_m1lulI
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: lud.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: lud.cu
## Adding new section PTX
Adding ptx filename: _cuobjdump_2.ptx
Adding arch: sm_13
Adding identifier: lud_kernel.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: lud_kernel.cu
Done parsing!!!
GPGPU-Sim PTX: __cudaRegisterFunction _Z12lud_internalPfii : hostFun 0x0x401c70, fat_cubin_handle = 1
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38676_33_non_const_shadow16" from 0x0 to 0x400 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z12lud_diagonalPfii'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: Finding dominators for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: Finding postdominators for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z12lud_diagonalPfii'...
GPGPU-Sim PTX: reconvergence points for _Z12lud_diagonalPfii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x3e0 (_1.ptx:200) @!%p1 bra $Lt_0_7682;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x520 (_1.ptx:248) bar.sync 0;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x3f8 (_1.ptx:203) @%p2 bra $Lt_0_11010;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x4f0 (_1.ptx:240) mov.f32 %f21, %f17;
GPGPU-Sim PTX:  3 (potential) branch divergence @  PC=0x4b0 (_1.ptx:229) @%p3 bra $Lt_0_8706;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x4b8 (_1.ptx:230) bra.uni $Lt_0_8194;
GPGPU-Sim PTX:  4 (potential) branch divergence @  PC=0x4b8 (_1.ptx:230) bra.uni $Lt_0_8194;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x4f0 (_1.ptx:240) mov.f32 %f21, %f17;
GPGPU-Sim PTX:  5 (potential) branch divergence @  PC=0x528 (_1.ptx:249) @!%p1 bra $Lt_0_9730;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x600 (_1.ptx:282) bar.sync 0;
GPGPU-Sim PTX:  6 (potential) branch divergence @  PC=0x548 (_1.ptx:253) @%p4 bra $Lt_0_9730;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x600 (_1.ptx:282) bar.sync 0;
GPGPU-Sim PTX:  7 (potential) branch divergence @  PC=0x5f8 (_1.ptx:278) @%p5 bra $Lt_0_10242;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x600 (_1.ptx:282) bar.sync 0;
GPGPU-Sim PTX:  8 (potential) branch divergence @  PC=0x628 (_1.ptx:287) @%p6 bra $Lt_0_7426;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x630 (_1.ptx:289) add.s32 %r47, %r1, 1;
GPGPU-Sim PTX: ... end of reconvergence points for _Z12lud_diagonalPfii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z12lud_diagonalPfii'.
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38718_33_non_const_peri_row1056" from 0x0 to 0x400 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38717_33_non_const_dia2080" from 0x400 to 0x800 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38719_33_non_const_peri_col3104" from 0x800 to 0xc00 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z13lud_perimeterPfii'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: Finding dominators for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: Finding postdominators for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z13lud_perimeterPfii'...
GPGPU-Sim PTX: reconvergence points for _Z13lud_perimeterPfii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x9d0 (_1.ptx:434) @!%p1 bra $Lt_1_13058;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1578 (_1.ptx:849) bar.sync 0;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0xfb8 (_1.ptx:639) bra.uni $Lt_1_12802;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1578 (_1.ptx:849) bar.sync 0;
GPGPU-Sim PTX:  3 (potential) branch divergence @  PC=0x1580 (_1.ptx:850) @!%p1 bra $Lt_1_13570;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1810 (_1.ptx:949) bar.sync 0;
GPGPU-Sim PTX:  4 (potential) branch divergence @  PC=0x15a0 (_1.ptx:856) @%p2 bra $Lt_1_14594;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1670 (_1.ptx:886) add.s32 %r117, %r117, 1;
GPGPU-Sim PTX:  5 (potential) branch divergence @  PC=0x1668 (_1.ptx:884) @%p3 bra $Lt_1_15106;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1670 (_1.ptx:886) add.s32 %r117, %r117, 1;
GPGPU-Sim PTX:  6 (potential) branch divergence @  PC=0x1688 (_1.ptx:889) @%p4 bra $Lt_1_14338;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1690 (_1.ptx:890) bra.uni $Lt_1_13314;
GPGPU-Sim PTX:  7 (potential) branch divergence @  PC=0x1690 (_1.ptx:890) bra.uni $Lt_1_13314;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1810 (_1.ptx:949) bar.sync 0;
GPGPU-Sim PTX:  8 (potential) branch divergence @  PC=0x16d8 (_1.ptx:902) @%p5 bra $Lt_1_18690;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x17c0 (_1.ptx:937) mov.f32 %f57, %f53;
GPGPU-Sim PTX:  9 (potential) branch divergence @  PC=0x1788 (_1.ptx:927) @%p6 bra $Lt_1_17154;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1790 (_1.ptx:928) bra.uni $Lt_1_16642;
GPGPU-Sim PTX: 10 (potential) branch divergence @  PC=0x1790 (_1.ptx:928) bra.uni $Lt_1_16642;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x17c0 (_1.ptx:937) mov.f32 %f57, %f53;
GPGPU-Sim PTX: 11 (potential) branch divergence @  PC=0x1808 (_1.ptx:946) @%p7 bra $Lt_1_16386;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1810 (_1.ptx:949) bar.sync 0;
GPGPU-Sim PTX: 12 (potential) branch divergence @  PC=0x1818 (_1.ptx:950) @!%p1 bra $Lt_1_18178;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1fc8 (_1.ptx:1227) exit;
GPGPU-Sim PTX: 13 (potential) branch divergence @  PC=0x1c10 (_1.ptx:1088) bra.uni $Lt_1_17922;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x1fc8 (_1.ptx:1227) exit;
GPGPU-Sim PTX: ... end of reconvergence points for _Z13lud_perimeterPfii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z13lud_perimeterPfii'.
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38828_33_non_const_peri_col4144" from 0x0 to 0x400 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "__cuda___cuda_local_var_38827_33_non_const_peri_row5168" from 0x400 to 0x800 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z12lud_internalPfii'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: Finding dominators for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: Finding postdominators for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z12lud_internalPfii'...
GPGPU-Sim PTX: reconvergence points for _Z12lud_internalPfii...
GPGPU-Sim PTX: ... end of reconvergence points for _Z12lud_internalPfii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z12lud_internalPfii'.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file _1.ptx
Adding _cuobjdump_2.ptx with cubin handle 1
GPGPU-Sim PTX: extracting embedded .ptx to temporary file "_ptx_FsWPeo"
Running: cat _ptx_FsWPeo | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_W91O56
GPGPU-Sim PTX: generating ptxinfo using "$CUDA_INSTALL_PATH/bin/ptxas --gpu-name=sm_20 -v _ptx2_W91O56 --output-file  /dev/null 2> _ptx_FsWPeoinfo"
GPGPU-Sim PTX: Kernel '_Z12lud_internalPfii' : regs=14, lmem=0, smem=2048, cmem=48
GPGPU-Sim PTX: Kernel '_Z13lud_perimeterPfii' : regs=32, lmem=0, smem=3072, cmem=56
GPGPU-Sim PTX: Kernel '_Z12lud_diagonalPfii' : regs=23, lmem=0, smem=1024, cmem=48
GPGPU-Sim PTX: removing ptxinfo using "rm -f _ptx_FsWPeo _ptx2_W91O56 _ptx_FsWPeoinfo"
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: __cudaRegisterFunction _Z13lud_perimeterPfii : hostFun 0x0x401cf0, fat_cubin_handle = 1
GPGPU-Sim PTX: __cudaRegisterFunction _Z12lud_diagonalPfii : hostFun 0x0x401d70, fat_cubin_handle = 1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 2, filename=lud.cu
Reading matrix from file ../data/lud/256.dat

GPGPU-Sim PTX: cudaLaunch for 0x0x401d70 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: pushing kernel '_Z12lud_diagonalPfii' to stream 0, gridDim= (1,1,1) blockDim = (16,1,1) 
kernel '_Z12lud_diagonalPfii' transfer to GPU hardware scheduler
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z12lud_diagonalPfii'
GPGPU-Sim uArch: CTA/core = 8, limited by: cta_limit
GPGPU-Sim uArch: core:  1, cta: 0 initialized @(1,0)
GPGPU-Sim uArch: cycles simulated: 500  inst.: 16 (ipc= 0.0) sim_rate=1 (inst/sec) elapsed = 0:0:00:11 / Tue Mar 22 07:37:03 2016
GPGPU-Sim uArch: cycles simulated: 1000  inst.: 256 (ipc= 0.3) sim_rate=21 (inst/sec) elapsed = 0:0:00:12 / Tue Mar 22 07:37:04 2016
GPGPU-Sim uArch: cycles simulated: 2500  inst.: 672 (ipc= 0.3) sim_rate=51 (inst/sec) elapsed = 0:0:00:13 / Tue Mar 22 07:37:05 2016
GPGPU-Sim uArch: cycles simulated: 4500  inst.: 1264 (ipc= 0.3) sim_rate=90 (inst/sec) elapsed = 0:0:00:14 / Tue Mar 22 07:37:06 2016
GPGPU-Sim uArch: cycles simulated: 6000  inst.: 1680 (ipc= 0.3) sim_rate=105 (inst/sec) elapsed = 0:0:00:16 / Tue Mar 22 07:37:08 2016
GPGPU-Sim uArch: cycles simulated: 23500  inst.: 20235 (ipc= 0.9) sim_rate=1190 (inst/sec) elapsed = 0:0:00:17 / Tue Mar 22 07:37:09 2016
GPGPU-Sim uArch: Shader 1 finished CTA #0 (27719,0), 0 CTAs running
GPGPU-Sim uArch: Shader 1 empty (release kernel 1 '_Z12lud_diagonalPfii').
GPGPU-Sim uArch: GPU detected kernel '_Z12lud_diagonalPfii' finished on shader 1.

GPGPU-Sim PTX: cudaLaunch for 0x0x401cf0 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: pushing kernel '_Z13lud_perimeterPfii' to stream 0, gridDim= (15,1,1) blockDim = (32,1,1) 
kernel_name = _Z12lud_diagonalPfii 
kernel_launch_uid = 1 
gpu_sim_cycle = 27720
gpu_sim_insn = 22350
gpu_ipc =       0.8063
gpu_tot_sim_cycle = 27720
gpu_tot_sim_insn = 22350
gpu_tot_ipc =       0.8063
gpu_tot_issued_cta = 1
gpu_stall_dramfull = 0
gpu_stall_icnt2sh    = 0
gpu_total_sim_rate=1314

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 1822
	L1I_total_cache_misses = 20
	L1I_total_cache_miss_rate = 0.0110
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 0
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 31, Miss = 16, Miss_rate = 0.516, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 31
	L1D_total_cache_misses = 16
	L1D_total_cache_miss_rate = 0.5161
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.001
	L1D_cache_fill_port_util = 0.001
L1C_cache:
	L1C_total_cache_accesses = 3
	L1C_total_cache_misses = 2
	L1C_total_cache_miss_rate = 0.6667
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 16
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 1
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 2
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 15
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 1802
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 20
Shader 0 warp_id issue ditsribution:
warp_id:

distro:

gpgpu_n_tot_thrd_icount = 102656
gpgpu_n_tot_w_icount = 3208
gpgpu_n_stall_shd_mem = 504
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 16
gpgpu_n_mem_write_global = 15
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 1
gpgpu_n_load_insn  = 256
gpgpu_n_store_insn = 240
gpgpu_n_shmem_insn = 4696
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 48
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[c_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 504
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:0	W0_Idle:35211	W0_Scoreboard:17049	W1:329	W2:309	W3:289	W4:269	W5:249	W6:229	W7:209	W8:189	W9:169	W10:149	W11:129	W12:109	W13:89	W14:69	W15:41	W16:381	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:0
traffic_breakdown_coretomem[CONST_ACC_R] = 8 {8:1,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 128 {8:16,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1080 {72:15,}
traffic_breakdown_coretomem[INST_ACC_R] = 160 {8:20,}
traffic_breakdown_memtocore[CONST_ACC_R] = 72 {72:1,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 2176 {136:16,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 120 {8:15,}
traffic_breakdown_memtocore[INST_ACC_R] = 2720 {136:20,}
maxmrqlatency = 1 
maxdqlatency = 0 
maxmflatency = 275 
averagemflatency = 207 
max_icnt2mem_latency = 11 
max_icnt2sh_latency = 27719 
mrq_lat_table:37 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	15 	17 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	52 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	17 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	15 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	5 	13 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:         1         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
maximum service time to same row:
dram[0]:       609      8696         0         0      1444         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:      2046     25722         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:      3831     26447         0         0         0       847         0         0         0         0         0         0         0         0         0         0 
dram[3]:      5615     27172         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:      7384         0         0         0      1763         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:      7972         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
average row accesses per activate:
dram[0]:  1.000000  2.000000      -nan      -nan  5.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[1]:  2.000000  2.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[2]:  2.000000  2.000000      -nan      -nan      -nan  6.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[3]:  2.000000  2.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[4]:  2.000000      -nan      -nan      -nan  5.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[5]:  2.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
average row locality = 37/15 = 2.466667
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:         3         2         0         0         5         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         2         2         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         2         2         0         0         0         6         0         0         0         0         0         0         0         0         0         0 
dram[3]:         2         2         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         2         0         0         0         5         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         2         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total reads: 37
min_bank_accesses = 0!
chip skew: 10/2 = 5.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total reads: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
average mf latency per bank:
dram[0]:         91         0    none      none         401    none      none      none      none      none      none      none      none      none      none      none  
dram[1]:          0         0    none      none      none      none      none      none      none      none      none      none      none      none      none      none  
dram[2]:          0         0    none      none      none         378    none      none      none      none      none      none      none      none      none      none  
dram[3]:          0         0    none      none      none      none      none      none      none      none      none      none      none      none      none      none  
dram[4]:          0    none      none      none         401    none      none      none      none      none      none      none      none      none      none      none  
dram[5]:          0    none      none      none      none      none      none      none      none      none      none      none      none      none      none      none  
maximum mf latency per bank:
dram[0]:        275         0         0         0       268         0         0         0         0         0         0         0         0         0         0         0
dram[1]:          0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0
dram[2]:          0         0         0         0         0       268         0         0         0         0         0         0         0         0         0         0
dram[3]:          0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0
dram[4]:          0         0         0         0       268         0         0         0         0         0         0         0         0         0         0         0
dram[5]:          0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36563 n_act=5 n_pre=2 n_req=10 n_rd=20 n_write=0 bw_util=0.001093
n_activity=299 dram_eff=0.1338
bk0: 6a 36519i bk1: 4a 36568i bk2: 0a 36590i bk3: 0a 36590i bk4: 10a 36557i bk5: 0a 36588i bk6: 0a 36588i bk7: 0a 36588i bk8: 0a 36589i bk9: 0a 36589i bk10: 0a 36591i bk11: 0a 36591i bk12: 0a 36591i bk13: 0a 36591i bk14: 0a 36591i bk15: 0a 36591i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36580 n_act=2 n_pre=0 n_req=4 n_rd=8 n_write=0 bw_util=0.0004373
n_activity=110 dram_eff=0.1455
bk0: 4a 36570i bk1: 4a 36570i bk2: 0a 36589i bk3: 0a 36590i bk4: 0a 36590i bk5: 0a 36590i bk6: 0a 36590i bk7: 0a 36590i bk8: 0a 36590i bk9: 0a 36590i bk10: 0a 36590i bk11: 0a 36590i bk12: 0a 36590i bk13: 0a 36590i bk14: 0a 36590i bk15: 0a 36590i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36567 n_act=3 n_pre=0 n_req=10 n_rd=20 n_write=0 bw_util=0.001093
n_activity=225 dram_eff=0.1778
bk0: 4a 36571i bk1: 4a 36570i bk2: 0a 36589i bk3: 0a 36589i bk4: 0a 36589i bk5: 12a 36552i bk6: 0a 36588i bk7: 0a 36588i bk8: 0a 36588i bk9: 0a 36590i bk10: 0a 36590i bk11: 0a 36591i bk12: 0a 36591i bk13: 0a 36591i bk14: 0a 36592i bk15: 0a 36592i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36580 n_act=2 n_pre=0 n_req=4 n_rd=8 n_write=0 bw_util=0.0004373
n_activity=110 dram_eff=0.1455
bk0: 4a 36570i bk1: 4a 36570i bk2: 0a 36589i bk3: 0a 36590i bk4: 0a 36590i bk5: 0a 36590i bk6: 0a 36590i bk7: 0a 36590i bk8: 0a 36590i bk9: 0a 36590i bk10: 0a 36590i bk11: 0a 36590i bk12: 0a 36590i bk13: 0a 36590i bk14: 0a 36590i bk15: 0a 36590i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36574 n_act=2 n_pre=0 n_req=7 n_rd=14 n_write=0 bw_util=0.0007652
n_activity=155 dram_eff=0.1806
bk0: 4a 36570i bk1: 0a 36590i bk2: 0a 36590i bk3: 0a 36590i bk4: 10a 36557i bk5: 0a 36588i bk6: 0a 36588i bk7: 0a 36588i bk8: 0a 36589i bk9: 0a 36590i bk10: 0a 36591i bk11: 0a 36591i bk12: 0a 36591i bk13: 0a 36591i bk14: 0a 36591i bk15: 0a 36591i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=36590 n_nop=36585 n_act=1 n_pre=0 n_req=2 n_rd=4 n_write=0 bw_util=0.0002186
n_activity=55 dram_eff=0.1455
bk0: 4a 36570i bk1: 0a 36590i bk2: 0a 36590i bk3: 0a 36590i bk4: 0a 36590i bk5: 0a 36590i bk6: 0a 36590i bk7: 0a 36590i bk8: 0a 36590i bk9: 0a 36590i bk10: 0a 36590i bk11: 0a 36590i bk12: 0a 36590i bk13: 0a 36590i bk14: 0a 36590i bk15: 0a 36590i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=0 avg=0

========= L2 cache stats =========
L2_cache_bank[0]: Access = 13, Miss = 8, Miss_rate = 0.615, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[1]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[2]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[3]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[4]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[5]: Access = 13, Miss = 8, Miss_rate = 0.615, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[6]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[7]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[8]: Access = 12, Miss = 7, Miss_rate = 0.583, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[10]: Access = 2, Miss = 2, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
L2_total_cache_accesses = 52
L2_total_cache_misses = 37
L2_total_cache_miss_rate = 0.7115
L2_total_cache_pending_hits = 0
L2_total_cache_reservation_fails = 0
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 16
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 15
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 20
L2_cache_data_port_util = 0.000
L2_cache_fill_port_util = 0.000

icnt_total_pkts_mem_to_simt=198
icnt_total_pkts_simt_to_mem=82
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 7.70192
	minimum = 6
	maximum = 11
Network latency average = 7.70192
	minimum = 6
	maximum = 11
Slowest packet = 27
Flit latency average = 6.01786
	minimum = 6
	maximum = 7
Slowest flit = 77
Fragmentation average = 0
	minimum = 0
	maximum = 0
Injected packet rate average = 0.000138956
	minimum = 0 (at node 0)
	maximum = 0.0018759 (at node 1)
Accepted packet rate average = 0.000138956
	minimum = 0 (at node 0)
	maximum = 0.0018759 (at node 1)
Injected flit rate average = 0.000374111
	minimum = 0 (at node 0)
	maximum = 0.00295815 (at node 1)
Accepted flit rate average= 0.000374111
	minimum = 0 (at node 0)
	maximum = 0.00714286 (at node 1)
Injected packet length average = 2.69231
Accepted packet length average = 2.69231
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 7.70192 (1 samples)
	minimum = 6 (1 samples)
	maximum = 11 (1 samples)
Network latency average = 7.70192 (1 samples)
	minimum = 6 (1 samples)
	maximum = 11 (1 samples)
Flit latency average = 6.01786 (1 samples)
	minimum = 6 (1 samples)
	maximum = 7 (1 samples)
Fragmentation average = 0 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0 (1 samples)
Injected packet rate average = 0.000138956 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0018759 (1 samples)
Accepted packet rate average = 0.000138956 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0018759 (1 samples)
Injected flit rate average = 0.000374111 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.00295815 (1 samples)
Accepted flit rate average = 0.000374111 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.00714286 (1 samples)
Injected packet size average = 2.69231 (1 samples)
Accepted packet size average = 2.69231 (1 samples)
Hops average = 1 (1 samples)
